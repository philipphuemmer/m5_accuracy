{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please input your directory for the top level folder\n",
    "folder name : SUBMISSION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T21:55:04.088683Z",
     "start_time": "2024-04-02T21:55:04.073682Z"
    }
   },
   "outputs": [],
   "source": [
    "dir_ = 'E:/Seminararbeit/Code/A1/' # input only here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T21:55:05.374683Z",
     "start_time": "2024-04-02T21:55:05.363683Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_data_dir = dir_+'2. data/'\n",
    "processed_data_dir = dir_+'2. data/processed/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Main setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T21:54:50.447686Z",
     "start_time": "2024-04-02T21:54:47.071761Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 8\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\u001B[38;5;241m,\u001B[39m \u001B[38;5;21;01msys\u001B[39;00m\u001B[38;5;241m,\u001B[39m \u001B[38;5;21;01mgc\u001B[39;00m\u001B[38;5;241m,\u001B[39m \u001B[38;5;21;01mtime\u001B[39;00m\u001B[38;5;241m,\u001B[39m \u001B[38;5;21;01mwarnings\u001B[39;00m\u001B[38;5;241m,\u001B[39m \u001B[38;5;21;01mpickle\u001B[39;00m\u001B[38;5;241m,\u001B[39m \u001B[38;5;21;01mpsutil\u001B[39;00m\u001B[38;5;241m,\u001B[39m \u001B[38;5;21;01mrandom\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmath\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ceil\n\u001B[1;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpreprocessing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LabelEncoder\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtqdm\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tqdm\n\u001B[0;32m     11\u001B[0m warnings\u001B[38;5;241m.\u001B[39mfilterwarnings(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys, gc, time, warnings, pickle, psutil, random\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T21:55:32.788416Z",
     "start_time": "2024-04-02T21:55:32.780416Z"
    }
   },
   "outputs": [],
   "source": [
    "## Simple \"Memory profilers\" to see memory usage\n",
    "def get_memory_usage():\n",
    "    return np.round(psutil.Process(os.getpid()).memory_info()[0]/2.**30, 2) \n",
    "        \n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f%s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f%s%s\" % (num, 'Yi', suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T21:55:30.175505Z",
     "start_time": "2024-04-02T21:55:30.157502Z"
    }
   },
   "outputs": [],
   "source": [
    "## Memory Reducer\n",
    "# :df pandas dataframe to reduce size             # type: pd.DataFrame()\n",
    "# :verbose                                        # type: bool\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                       df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T21:55:29.164355Z",
     "start_time": "2024-04-02T21:55:29.145355Z"
    }
   },
   "outputs": [],
   "source": [
    "## Merging by concat to not lose dtypes\n",
    "def merge_by_concat(df1, df2, merge_on):\n",
    "    merged_gf = df1[merge_on]\n",
    "    merged_gf = merged_gf.merge(df2, on=merge_on, how='left')\n",
    "    new_columns = [col for col in list(merged_gf) if col not in merge_on]\n",
    "    df1 = pd.concat([df1, merged_gf[new_columns]], axis=1)\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T21:55:27.401801Z",
     "start_time": "2024-04-02T21:55:27.389802Z"
    }
   },
   "outputs": [],
   "source": [
    "########################### Vars\n",
    "#################################################################################\n",
    "TARGET = 'sales'         # Our main target\n",
    "END_TRAIN = 1941         # Last day in train set\n",
    "MAIN_INDEX = ['id','d']  # We can identify item by these columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Part 1\n",
    "- Melting train data => grid_part_1\n",
    "- creating price features => grid_part_2\n",
    "- creating calendar features => grid_part_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T19:15:52.170550Z",
     "start_time": "2024-04-02T19:15:46.699376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Main Data\n"
     ]
    }
   ],
   "source": [
    "########################### Load Data\n",
    "#################################################################################\n",
    "print('Load Main Data')\n",
    "\n",
    "# Here are reafing all our data \n",
    "# without any limitations and dtype modification\n",
    "train_df = pd.read_csv(raw_data_dir+'sales_train_evaluation.csv')\n",
    "prices_df = pd.read_csv(raw_data_dir+'sell_prices.csv')\n",
    "calendar_df = pd.read_csv(raw_data_dir+'calendar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T19:18:10.170308Z",
     "start_time": "2024-04-02T19:17:14.811456Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Grid\n"
     ]
    },
    {
     "data": {
      "text/plain": "                              id        item_id    dept_id   cat_id store_id  \\\n0  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n1  HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n2  HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n3  HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n4  HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n\n  state_id    d  sales  \n0       CA  d_1      0  \n1       CA  d_1      0  \n2       CA  d_1      0  \n3       CA  d_1      0  \n4       CA  d_1      0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>item_id</th>\n      <th>dept_id</th>\n      <th>cat_id</th>\n      <th>store_id</th>\n      <th>state_id</th>\n      <th>d</th>\n      <th>sales</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HOBBIES_1_001_CA_1_evaluation</td>\n      <td>HOBBIES_1_001</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HOBBIES_1_002_CA_1_evaluation</td>\n      <td>HOBBIES_1_002</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HOBBIES_1_003_CA_1_evaluation</td>\n      <td>HOBBIES_1_003</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HOBBIES_1_004_CA_1_evaluation</td>\n      <td>HOBBIES_1_004</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HOBBIES_1_005_CA_1_evaluation</td>\n      <td>HOBBIES_1_005</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 30490 59181090\n",
      "    Original grid_df:   3.6GiB\n",
      "     Reduced grid_df:   1.3GiB\n"
     ]
    }
   ],
   "source": [
    "########################### Make Grid\n",
    "#################################################################################\n",
    "print('Create Grid')\n",
    "\n",
    "# We can tranform horizontal representation representation 바꾸기\n",
    "# to vertical \"view\"\n",
    "# Our \"index\" will be 'id','item_id','dept_id','cat_id','store_id','state_id'\n",
    "# and labels are 'd_' coulmns\n",
    "\n",
    "index_columns = ['id','item_id','dept_id','cat_id','store_id','state_id']\n",
    "grid_df = pd.melt(train_df, \n",
    "                  id_vars = index_columns, \n",
    "                  var_name = 'd', \n",
    "                  value_name = TARGET)\n",
    "\n",
    "\n",
    "display(grid_df.head())\n",
    "\n",
    "# If we look on train_df we se that \n",
    "# we don't have a lot of traning rows\n",
    "# but each day can provide more train data\n",
    "print('Train rows:', len(train_df), len(grid_df))\n",
    "\n",
    "# To be able to make predictions\n",
    "# we need to add \"test set\" to our grid\n",
    "add_grid = pd.DataFrame()\n",
    "for i in range(1,29):\n",
    "    temp_df = train_df[index_columns]\n",
    "    temp_df = temp_df.drop_duplicates()\n",
    "    temp_df['d'] = 'd_'+ str(END_TRAIN+i)\n",
    "    temp_df[TARGET] = np.nan\n",
    "    add_grid = pd.concat([add_grid,temp_df])\n",
    "\n",
    "grid_df = pd.concat([grid_df,add_grid])\n",
    "grid_df = grid_df.reset_index(drop=True)\n",
    "\n",
    "# Remove some temoprary DFs\n",
    "del temp_df, add_grid\n",
    "\n",
    "# We will not need original train_df\n",
    "# anymore and can remove it\n",
    "del train_df\n",
    "\n",
    "# You don't have to use df = df construction\n",
    "# you can use inplace=True instead.\n",
    "# like this\n",
    "# grid_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Let's check our memory usage\n",
    "print(\"{:>20}: {:>8}\".format('Original grid_df',sizeof_fmt(grid_df.memory_usage(index=True).sum())))\n",
    "\n",
    "# We can free some memory \n",
    "# by converting \"strings\" to categorical\n",
    "# it will not affect merging and \n",
    "# we will not lose any valuable data\n",
    "for col in index_columns:\n",
    "    grid_df[col] = grid_df[col].astype('category')\n",
    "\n",
    "# Let's check again memory usage\n",
    "print(\"{:>20}: {:>8}\".format('Reduced grid_df',sizeof_fmt(grid_df.memory_usage(index=True).sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T19:54:52.183773Z",
     "start_time": "2024-04-02T19:54:18.642040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Release week\n"
     ]
    },
    {
     "data": {
      "text/plain": "  store_id      item_id  release\n0     CA_1  FOODS_1_001    11101\n1     CA_1  FOODS_1_002    11101\n2     CA_1  FOODS_1_003    11101\n3     CA_1  FOODS_1_004    11206\n4     CA_1  FOODS_1_005    11101",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>store_id</th>\n      <th>item_id</th>\n      <th>release</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CA_1</td>\n      <td>FOODS_1_001</td>\n      <td>11101</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CA_1</td>\n      <td>FOODS_1_002</td>\n      <td>11101</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CA_1</td>\n      <td>FOODS_1_003</td>\n      <td>11101</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CA_1</td>\n      <td>FOODS_1_004</td>\n      <td>11206</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CA_1</td>\n      <td>FOODS_1_005</td>\n      <td>11101</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                              id        item_id    dept_id   cat_id store_id  \\\n0  HOBBIES_1_008_CA_1_evaluation  HOBBIES_1_008  HOBBIES_1  HOBBIES     CA_1   \n1  HOBBIES_1_009_CA_1_evaluation  HOBBIES_1_009  HOBBIES_1  HOBBIES     CA_1   \n2  HOBBIES_1_010_CA_1_evaluation  HOBBIES_1_010  HOBBIES_1  HOBBIES     CA_1   \n3  HOBBIES_1_012_CA_1_evaluation  HOBBIES_1_012  HOBBIES_1  HOBBIES     CA_1   \n4  HOBBIES_1_015_CA_1_evaluation  HOBBIES_1_015  HOBBIES_1  HOBBIES     CA_1   \n\n  state_id    d  sales  release  wm_yr_wk  \n0       CA  d_1   12.0    11101     11101  \n1       CA  d_1    2.0    11101     11101  \n2       CA  d_1    0.0    11101     11101  \n3       CA  d_1    0.0    11101     11101  \n4       CA  d_1    4.0    11101     11101  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>item_id</th>\n      <th>dept_id</th>\n      <th>cat_id</th>\n      <th>store_id</th>\n      <th>state_id</th>\n      <th>d</th>\n      <th>sales</th>\n      <th>release</th>\n      <th>wm_yr_wk</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HOBBIES_1_008_CA_1_evaluation</td>\n      <td>HOBBIES_1_008</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1</td>\n      <td>12.0</td>\n      <td>11101</td>\n      <td>11101</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HOBBIES_1_009_CA_1_evaluation</td>\n      <td>HOBBIES_1_009</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1</td>\n      <td>2.0</td>\n      <td>11101</td>\n      <td>11101</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HOBBIES_1_010_CA_1_evaluation</td>\n      <td>HOBBIES_1_010</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1</td>\n      <td>0.0</td>\n      <td>11101</td>\n      <td>11101</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HOBBIES_1_012_CA_1_evaluation</td>\n      <td>HOBBIES_1_012</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1</td>\n      <td>0.0</td>\n      <td>11101</td>\n      <td>11101</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HOBBIES_1_015_CA_1_evaluation</td>\n      <td>HOBBIES_1_015</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1</td>\n      <td>4.0</td>\n      <td>11101</td>\n      <td>11101</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Original grid_df:   1.8GiB\n"
     ]
    },
    {
     "data": {
      "text/plain": "                              id        item_id    dept_id   cat_id store_id  \\\n0  HOBBIES_1_008_CA_1_evaluation  HOBBIES_1_008  HOBBIES_1  HOBBIES     CA_1   \n1  HOBBIES_1_009_CA_1_evaluation  HOBBIES_1_009  HOBBIES_1  HOBBIES     CA_1   \n2  HOBBIES_1_010_CA_1_evaluation  HOBBIES_1_010  HOBBIES_1  HOBBIES     CA_1   \n3  HOBBIES_1_012_CA_1_evaluation  HOBBIES_1_012  HOBBIES_1  HOBBIES     CA_1   \n4  HOBBIES_1_015_CA_1_evaluation  HOBBIES_1_015  HOBBIES_1  HOBBIES     CA_1   \n\n  state_id    d  sales  release  wm_yr_wk  \n0       CA  d_1   12.0        0     11101  \n1       CA  d_1    2.0        0     11101  \n2       CA  d_1    0.0        0     11101  \n3       CA  d_1    0.0        0     11101  \n4       CA  d_1    4.0        0     11101  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>item_id</th>\n      <th>dept_id</th>\n      <th>cat_id</th>\n      <th>store_id</th>\n      <th>state_id</th>\n      <th>d</th>\n      <th>sales</th>\n      <th>release</th>\n      <th>wm_yr_wk</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HOBBIES_1_008_CA_1_evaluation</td>\n      <td>HOBBIES_1_008</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1</td>\n      <td>12.0</td>\n      <td>0</td>\n      <td>11101</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HOBBIES_1_009_CA_1_evaluation</td>\n      <td>HOBBIES_1_009</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>11101</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HOBBIES_1_010_CA_1_evaluation</td>\n      <td>HOBBIES_1_010</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>11101</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HOBBIES_1_012_CA_1_evaluation</td>\n      <td>HOBBIES_1_012</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>11101</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HOBBIES_1_015_CA_1_evaluation</td>\n      <td>HOBBIES_1_015</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1</td>\n      <td>4.0</td>\n      <td>0</td>\n      <td>11101</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Reduced grid_df:   1.5GiB\n"
     ]
    }
   ],
   "source": [
    "########################### Product Release date\n",
    "#################################################################################\n",
    "print('Release week')\n",
    "\n",
    "# It seems that leadings zero values\n",
    "# in each train_df item row\n",
    "# are not real 0 sales but mean\n",
    "# absence for the item in the store\n",
    "# we can safe some memory by removing\n",
    "# such zeros\n",
    "\n",
    "# Prices are set by week\n",
    "# so it we will have not very accurate release week \n",
    "release_df = prices_df.groupby(['store_id','item_id'])['wm_yr_wk'].agg(['min']).reset_index()\n",
    "release_df.columns = ['store_id','item_id','release']\n",
    "\n",
    "display(release_df.head())\n",
    "\n",
    "# Now we can merge release_df\n",
    "grid_df = merge_by_concat(grid_df, release_df, ['store_id','item_id'])\n",
    "del release_df\n",
    "\n",
    "# We want to remove some \"zeros\" rows\n",
    "# from grid_df \n",
    "# to do it we need wm_yr_wk column\n",
    "# let's merge partly calendar_df to have it\n",
    "grid_df = merge_by_concat(grid_df, calendar_df[['wm_yr_wk','d']], ['d'])\n",
    "                      \n",
    "# Now we can cutoff some rows \n",
    "# and safe memory \n",
    "grid_df = grid_df[grid_df['wm_yr_wk']>=grid_df['release']]\n",
    "grid_df = grid_df.reset_index(drop=True)\n",
    "\n",
    "display(grid_df.head())\n",
    "\n",
    "# Let's check our memory usage\n",
    "print(\"{:>20}: {:>8}\".format('Original grid_df',sizeof_fmt(grid_df.memory_usage(index=True).sum())))\n",
    "\n",
    "# Should we keep release week \n",
    "# as one of the features?\n",
    "# Only good CV can give the answer.\n",
    "# Let's minify the release values.\n",
    "# Min transformation will not help here \n",
    "# as int16 -> Integer (-32768 to 32767)\n",
    "# and our grid_df['release'].max() serves for int16\n",
    "# but we have have an idea how to transform \n",
    "# other columns in case we will need it\n",
    "grid_df['release'] = grid_df['release'] - grid_df['release'].min()\n",
    "grid_df['release'] = grid_df['release'].astype(np.int16)\n",
    "\n",
    "\n",
    "display(grid_df.head())\n",
    "# Let's check again memory usage\n",
    "print(\"{:>20}: {:>8}\".format('Reduced grid_df',sizeof_fmt(grid_df.memory_usage(index=True).sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T21:42:26.153095Z",
     "start_time": "2024-03-12T21:42:17.201026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save Part 1\n",
      "Size: (47735397, 10)\n"
     ]
    }
   ],
   "source": [
    "########################### Save part 1\n",
    "#################################################################################\n",
    "print('Save Part 1')\n",
    "\n",
    "# We have our BASE grid ready\n",
    "# and can save it as pickle file\n",
    "# for future use (model training)\n",
    "grid_df.to_pickle(processed_data_dir+'grid_part_1.pkl')\n",
    "\n",
    "print('Size:', grid_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T20:14:43.764443Z",
     "start_time": "2024-04-02T20:14:30.232706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prices\n"
     ]
    },
    {
     "data": {
      "text/plain": "  store_id        item_id  wm_yr_wk  sell_price  price_max  price_min  \\\n0     CA_1  HOBBIES_1_001     11325        9.58       9.58       8.26   \n1     CA_1  HOBBIES_1_001     11326        9.58       9.58       8.26   \n2     CA_1  HOBBIES_1_001     11327        8.26       9.58       8.26   \n3     CA_1  HOBBIES_1_001     11328        8.26       9.58       8.26   \n4     CA_1  HOBBIES_1_001     11329        8.26       9.58       8.26   \n\n   price_std  price_mean  price_norm  price_nunique  item_nunique  \n0   0.152139    8.285714    1.000000              3             3  \n1   0.152139    8.285714    1.000000              3             3  \n2   0.152139    8.285714    0.862213              3             5  \n3   0.152139    8.285714    0.862213              3             5  \n4   0.152139    8.285714    0.862213              3             5  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>store_id</th>\n      <th>item_id</th>\n      <th>wm_yr_wk</th>\n      <th>sell_price</th>\n      <th>price_max</th>\n      <th>price_min</th>\n      <th>price_std</th>\n      <th>price_mean</th>\n      <th>price_norm</th>\n      <th>price_nunique</th>\n      <th>item_nunique</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CA_1</td>\n      <td>HOBBIES_1_001</td>\n      <td>11325</td>\n      <td>9.58</td>\n      <td>9.58</td>\n      <td>8.26</td>\n      <td>0.152139</td>\n      <td>8.285714</td>\n      <td>1.000000</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CA_1</td>\n      <td>HOBBIES_1_001</td>\n      <td>11326</td>\n      <td>9.58</td>\n      <td>9.58</td>\n      <td>8.26</td>\n      <td>0.152139</td>\n      <td>8.285714</td>\n      <td>1.000000</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CA_1</td>\n      <td>HOBBIES_1_001</td>\n      <td>11327</td>\n      <td>8.26</td>\n      <td>9.58</td>\n      <td>8.26</td>\n      <td>0.152139</td>\n      <td>8.285714</td>\n      <td>0.862213</td>\n      <td>3</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CA_1</td>\n      <td>HOBBIES_1_001</td>\n      <td>11328</td>\n      <td>8.26</td>\n      <td>9.58</td>\n      <td>8.26</td>\n      <td>0.152139</td>\n      <td>8.285714</td>\n      <td>0.862213</td>\n      <td>3</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CA_1</td>\n      <td>HOBBIES_1_001</td>\n      <td>11329</td>\n      <td>8.26</td>\n      <td>9.58</td>\n      <td>8.26</td>\n      <td>0.152139</td>\n      <td>8.285714</td>\n      <td>0.862213</td>\n      <td>3</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  store_id        item_id  wm_yr_wk  sell_price  price_max  price_min  \\\n0     CA_1  HOBBIES_1_001     11325        9.58       9.58       8.26   \n1     CA_1  HOBBIES_1_001     11326        9.58       9.58       8.26   \n2     CA_1  HOBBIES_1_001     11327        8.26       9.58       8.26   \n3     CA_1  HOBBIES_1_001     11328        8.26       9.58       8.26   \n4     CA_1  HOBBIES_1_001     11329        8.26       9.58       8.26   \n\n   price_std  price_mean  price_norm  price_nunique  item_nunique  month  year  \n0   0.152139    8.285714    1.000000              3             3      7  2013  \n1   0.152139    8.285714    1.000000              3             3      7  2013  \n2   0.152139    8.285714    0.862213              3             5      7  2013  \n3   0.152139    8.285714    0.862213              3             5      8  2013  \n4   0.152139    8.285714    0.862213              3             5      8  2013  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>store_id</th>\n      <th>item_id</th>\n      <th>wm_yr_wk</th>\n      <th>sell_price</th>\n      <th>price_max</th>\n      <th>price_min</th>\n      <th>price_std</th>\n      <th>price_mean</th>\n      <th>price_norm</th>\n      <th>price_nunique</th>\n      <th>item_nunique</th>\n      <th>month</th>\n      <th>year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CA_1</td>\n      <td>HOBBIES_1_001</td>\n      <td>11325</td>\n      <td>9.58</td>\n      <td>9.58</td>\n      <td>8.26</td>\n      <td>0.152139</td>\n      <td>8.285714</td>\n      <td>1.000000</td>\n      <td>3</td>\n      <td>3</td>\n      <td>7</td>\n      <td>2013</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CA_1</td>\n      <td>HOBBIES_1_001</td>\n      <td>11326</td>\n      <td>9.58</td>\n      <td>9.58</td>\n      <td>8.26</td>\n      <td>0.152139</td>\n      <td>8.285714</td>\n      <td>1.000000</td>\n      <td>3</td>\n      <td>3</td>\n      <td>7</td>\n      <td>2013</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CA_1</td>\n      <td>HOBBIES_1_001</td>\n      <td>11327</td>\n      <td>8.26</td>\n      <td>9.58</td>\n      <td>8.26</td>\n      <td>0.152139</td>\n      <td>8.285714</td>\n      <td>0.862213</td>\n      <td>3</td>\n      <td>5</td>\n      <td>7</td>\n      <td>2013</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CA_1</td>\n      <td>HOBBIES_1_001</td>\n      <td>11328</td>\n      <td>8.26</td>\n      <td>9.58</td>\n      <td>8.26</td>\n      <td>0.152139</td>\n      <td>8.285714</td>\n      <td>0.862213</td>\n      <td>3</td>\n      <td>5</td>\n      <td>8</td>\n      <td>2013</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CA_1</td>\n      <td>HOBBIES_1_001</td>\n      <td>11329</td>\n      <td>8.26</td>\n      <td>9.58</td>\n      <td>8.26</td>\n      <td>0.152139</td>\n      <td>8.285714</td>\n      <td>0.862213</td>\n      <td>3</td>\n      <td>5</td>\n      <td>8</td>\n      <td>2013</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  store_id        item_id  wm_yr_wk  sell_price  price_max  price_min  \\\n0     CA_1  HOBBIES_1_001     11325        9.58       9.58       8.26   \n1     CA_1  HOBBIES_1_001     11326        9.58       9.58       8.26   \n2     CA_1  HOBBIES_1_001     11327        8.26       9.58       8.26   \n3     CA_1  HOBBIES_1_001     11328        8.26       9.58       8.26   \n4     CA_1  HOBBIES_1_001     11329        8.26       9.58       8.26   \n\n   price_std  price_mean  price_norm  price_nunique  item_nunique  month  \\\n0   0.152139    8.285714    1.000000              3             3      7   \n1   0.152139    8.285714    1.000000              3             3      7   \n2   0.152139    8.285714    0.862213              3             5      7   \n3   0.152139    8.285714    0.862213              3             5      8   \n4   0.152139    8.285714    0.862213              3             5      8   \n\n   year  price_momentum  price_momentum_m  price_momentum_y  \n0  2013             NaN          1.127059          1.145166  \n1  2013        1.000000          1.127059          1.145166  \n2  2013        0.862213          0.971765          0.987377  \n3  2013        1.000000          1.000000          0.987377  \n4  2013        1.000000          1.000000          0.987377  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>store_id</th>\n      <th>item_id</th>\n      <th>wm_yr_wk</th>\n      <th>sell_price</th>\n      <th>price_max</th>\n      <th>price_min</th>\n      <th>price_std</th>\n      <th>price_mean</th>\n      <th>price_norm</th>\n      <th>price_nunique</th>\n      <th>item_nunique</th>\n      <th>month</th>\n      <th>year</th>\n      <th>price_momentum</th>\n      <th>price_momentum_m</th>\n      <th>price_momentum_y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CA_1</td>\n      <td>HOBBIES_1_001</td>\n      <td>11325</td>\n      <td>9.58</td>\n      <td>9.58</td>\n      <td>8.26</td>\n      <td>0.152139</td>\n      <td>8.285714</td>\n      <td>1.000000</td>\n      <td>3</td>\n      <td>3</td>\n      <td>7</td>\n      <td>2013</td>\n      <td>NaN</td>\n      <td>1.127059</td>\n      <td>1.145166</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CA_1</td>\n      <td>HOBBIES_1_001</td>\n      <td>11326</td>\n      <td>9.58</td>\n      <td>9.58</td>\n      <td>8.26</td>\n      <td>0.152139</td>\n      <td>8.285714</td>\n      <td>1.000000</td>\n      <td>3</td>\n      <td>3</td>\n      <td>7</td>\n      <td>2013</td>\n      <td>1.000000</td>\n      <td>1.127059</td>\n      <td>1.145166</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CA_1</td>\n      <td>HOBBIES_1_001</td>\n      <td>11327</td>\n      <td>8.26</td>\n      <td>9.58</td>\n      <td>8.26</td>\n      <td>0.152139</td>\n      <td>8.285714</td>\n      <td>0.862213</td>\n      <td>3</td>\n      <td>5</td>\n      <td>7</td>\n      <td>2013</td>\n      <td>0.862213</td>\n      <td>0.971765</td>\n      <td>0.987377</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CA_1</td>\n      <td>HOBBIES_1_001</td>\n      <td>11328</td>\n      <td>8.26</td>\n      <td>9.58</td>\n      <td>8.26</td>\n      <td>0.152139</td>\n      <td>8.285714</td>\n      <td>0.862213</td>\n      <td>3</td>\n      <td>5</td>\n      <td>8</td>\n      <td>2013</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987377</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CA_1</td>\n      <td>HOBBIES_1_001</td>\n      <td>11329</td>\n      <td>8.26</td>\n      <td>9.58</td>\n      <td>8.26</td>\n      <td>0.152139</td>\n      <td>8.285714</td>\n      <td>0.862213</td>\n      <td>3</td>\n      <td>5</td>\n      <td>8</td>\n      <td>2013</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987377</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################### Prices\n",
    "#################################################################################\n",
    "print('Prices')\n",
    "\n",
    "# We can do some basic aggregations\n",
    "prices_df['price_max'] = prices_df.groupby(['store_id','item_id'])['sell_price'].transform('max')\n",
    "prices_df['price_min'] = prices_df.groupby(['store_id','item_id'])['sell_price'].transform('min')\n",
    "prices_df['price_std'] = prices_df.groupby(['store_id','item_id'])['sell_price'].transform('std')\n",
    "prices_df['price_mean'] = prices_df.groupby(['store_id','item_id'])['sell_price'].transform('mean')\n",
    "\n",
    "# and do price normalization (min/max scaling)\n",
    "prices_df['price_norm'] = prices_df['sell_price']/prices_df['price_max']\n",
    "\n",
    "# Some items are can be inflation dependent\n",
    "# and some items are very \"stable\"\n",
    "\n",
    "prices_df['price_nunique'] = prices_df.groupby(['store_id','item_id'])['sell_price'].transform('nunique') \n",
    "prices_df['item_nunique'] = prices_df.groupby(['store_id','sell_price'])['item_id'].transform('nunique')\n",
    "\n",
    "display(prices_df.head())\n",
    "\n",
    "# I would like some \"rolling\" aggregations\n",
    "# but would like months and years as \"window\"\n",
    "calendar_prices = calendar_df[['wm_yr_wk','month','year']]\n",
    "calendar_prices = calendar_prices.drop_duplicates(subset=['wm_yr_wk']) # distinct(.keep_all = True)\n",
    "prices_df = prices_df.merge(calendar_prices[['wm_yr_wk','month','year']], on=['wm_yr_wk'], how='left')\n",
    "del calendar_prices\n",
    "\n",
    "display(prices_df.head())\n",
    "\n",
    "# Now we can add price \"momentum\" (some sort of)\n",
    "# Shifted by week \n",
    "# by month mean\n",
    "# by year mean\n",
    "prices_df['price_momentum'] = prices_df['sell_price']/prices_df.groupby(['store_id','item_id'])['sell_price'].transform(lambda x: x.shift(1))\n",
    "prices_df['price_momentum_m'] = prices_df['sell_price']/prices_df.groupby(['store_id','item_id','month'])['sell_price'].transform('mean')\n",
    "prices_df['price_momentum_y'] = prices_df['sell_price']/prices_df.groupby(['store_id','item_id','year'])['sell_price'].transform('mean')\n",
    "\n",
    "display(prices_df.head())\n",
    "\n",
    "del prices_df['month'], prices_df['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T21:43:27.724320Z",
     "start_time": "2024-03-12T21:43:26.291481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1002.86 Mb (35.3% reduction)\n",
      "Mem. usage decreased to 254.44 Mb (65.2% reduction)\n"
     ]
    }
   ],
   "source": [
    "grid_df = reduce_mem_usage(grid_df)\n",
    "prices_df = reduce_mem_usage(prices_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T20:24:30.773413Z",
     "start_time": "2024-04-02T20:22:52.658223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge prices and save part 2\n",
      "Mem. usage decreased to 1412.49 Mb (68.3% reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                              id    d  sell_price  price_max  price_min  \\\n0  HOBBIES_1_008_CA_1_evaluation  d_1    0.459961   0.500000   0.419922   \n1  HOBBIES_1_009_CA_1_evaluation  d_1    1.559570   1.769531   1.559570   \n2  HOBBIES_1_010_CA_1_evaluation  d_1    3.169922   3.169922   2.970703   \n3  HOBBIES_1_012_CA_1_evaluation  d_1    5.980469   6.519531   5.980469   \n4  HOBBIES_1_015_CA_1_evaluation  d_1    0.700195   0.720215   0.680176   \n\n   price_std  price_mean  price_norm  price_nunique  item_nunique  \\\n0   0.019760    0.476318    0.919922              4            16   \n1   0.032745    1.764648    0.881348              2             9   \n2   0.046356    2.980469    1.000000              2            20   \n3   0.115967    6.468750    0.916992              3            71   \n4   0.011337    0.706543    0.972168              3            16   \n\n   price_momentum  price_momentum_m  price_momentum_y  \n0             NaN          0.968750          0.949219  \n1             NaN          0.885742          0.896484  \n2             NaN          1.064453          1.043945  \n3             NaN          0.921875          0.958984  \n4             NaN          0.990234          1.001953  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>d</th>\n      <th>sell_price</th>\n      <th>price_max</th>\n      <th>price_min</th>\n      <th>price_std</th>\n      <th>price_mean</th>\n      <th>price_norm</th>\n      <th>price_nunique</th>\n      <th>item_nunique</th>\n      <th>price_momentum</th>\n      <th>price_momentum_m</th>\n      <th>price_momentum_y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HOBBIES_1_008_CA_1_evaluation</td>\n      <td>d_1</td>\n      <td>0.459961</td>\n      <td>0.500000</td>\n      <td>0.419922</td>\n      <td>0.019760</td>\n      <td>0.476318</td>\n      <td>0.919922</td>\n      <td>4</td>\n      <td>16</td>\n      <td>NaN</td>\n      <td>0.968750</td>\n      <td>0.949219</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HOBBIES_1_009_CA_1_evaluation</td>\n      <td>d_1</td>\n      <td>1.559570</td>\n      <td>1.769531</td>\n      <td>1.559570</td>\n      <td>0.032745</td>\n      <td>1.764648</td>\n      <td>0.881348</td>\n      <td>2</td>\n      <td>9</td>\n      <td>NaN</td>\n      <td>0.885742</td>\n      <td>0.896484</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HOBBIES_1_010_CA_1_evaluation</td>\n      <td>d_1</td>\n      <td>3.169922</td>\n      <td>3.169922</td>\n      <td>2.970703</td>\n      <td>0.046356</td>\n      <td>2.980469</td>\n      <td>1.000000</td>\n      <td>2</td>\n      <td>20</td>\n      <td>NaN</td>\n      <td>1.064453</td>\n      <td>1.043945</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HOBBIES_1_012_CA_1_evaluation</td>\n      <td>d_1</td>\n      <td>5.980469</td>\n      <td>6.519531</td>\n      <td>5.980469</td>\n      <td>0.115967</td>\n      <td>6.468750</td>\n      <td>0.916992</td>\n      <td>3</td>\n      <td>71</td>\n      <td>NaN</td>\n      <td>0.921875</td>\n      <td>0.958984</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HOBBIES_1_015_CA_1_evaluation</td>\n      <td>d_1</td>\n      <td>0.700195</td>\n      <td>0.720215</td>\n      <td>0.680176</td>\n      <td>0.011337</td>\n      <td>0.706543</td>\n      <td>0.972168</td>\n      <td>3</td>\n      <td>16</td>\n      <td>NaN</td>\n      <td>0.990234</td>\n      <td>1.001953</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: (47735397, 13)\n"
     ]
    }
   ],
   "source": [
    "########################### Merge prices and save part 2\n",
    "#################################################################################\n",
    "print('Merge prices and save part 2')\n",
    "\n",
    "# Merge Prices\n",
    "original_columns = list(grid_df)\n",
    "grid_df = grid_df.merge(prices_df, on=['store_id','item_id','wm_yr_wk'], how='left')\n",
    "keep_columns = [col for col in list(grid_df) if col not in original_columns]\n",
    "grid_df = grid_df[MAIN_INDEX+keep_columns]\n",
    "grid_df = reduce_mem_usage(grid_df)\n",
    "\n",
    "display(grid_df.head())\n",
    "\n",
    "# Safe part 2\n",
    "grid_df.to_pickle(processed_data_dir+'grid_part_2.pkl')\n",
    "print('Size:', grid_df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T21:44:13.468455Z",
     "start_time": "2024-03-12T21:44:10.142225Z"
    }
   },
   "outputs": [],
   "source": [
    "# We don't need prices_df anymore\n",
    "del prices_df, grid_df\n",
    "\n",
    "# We can remove new columns\n",
    "# or just load part_1\n",
    "grid_df = pd.read_pickle(processed_data_dir+'grid_part_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T20:47:09.543255Z",
     "start_time": "2024-04-02T20:46:23.403365Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                              id    d       date event_name_1 event_type_1  \\\n0  HOBBIES_1_008_CA_1_evaluation  d_1 2011-01-29          NaN          NaN   \n1  HOBBIES_1_009_CA_1_evaluation  d_1 2011-01-29          NaN          NaN   \n2  HOBBIES_1_010_CA_1_evaluation  d_1 2011-01-29          NaN          NaN   \n3  HOBBIES_1_012_CA_1_evaluation  d_1 2011-01-29          NaN          NaN   \n4  HOBBIES_1_015_CA_1_evaluation  d_1 2011-01-29          NaN          NaN   \n\n  event_name_2 event_type_2 snap_CA snap_TX snap_WI  tm_d  tm_w  tm_m  tm_y  \\\n0          NaN          NaN       0       0       0    29     4     1     0   \n1          NaN          NaN       0       0       0    29     4     1     0   \n2          NaN          NaN       0       0       0    29     4     1     0   \n3          NaN          NaN       0       0       0    29     4     1     0   \n4          NaN          NaN       0       0       0    29     4     1     0   \n\n   tm_wm  tm_dw  tm_w_end  \n0      5      5         1  \n1      5      5         1  \n2      5      5         1  \n3      5      5         1  \n4      5      5         1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>d</th>\n      <th>date</th>\n      <th>event_name_1</th>\n      <th>event_type_1</th>\n      <th>event_name_2</th>\n      <th>event_type_2</th>\n      <th>snap_CA</th>\n      <th>snap_TX</th>\n      <th>snap_WI</th>\n      <th>tm_d</th>\n      <th>tm_w</th>\n      <th>tm_m</th>\n      <th>tm_y</th>\n      <th>tm_wm</th>\n      <th>tm_dw</th>\n      <th>tm_w_end</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HOBBIES_1_008_CA_1_evaluation</td>\n      <td>d_1</td>\n      <td>2011-01-29</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>29</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>5</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HOBBIES_1_009_CA_1_evaluation</td>\n      <td>d_1</td>\n      <td>2011-01-29</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>29</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>5</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HOBBIES_1_010_CA_1_evaluation</td>\n      <td>d_1</td>\n      <td>2011-01-29</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>29</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>5</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HOBBIES_1_012_CA_1_evaluation</td>\n      <td>d_1</td>\n      <td>2011-01-29</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>29</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>5</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HOBBIES_1_015_CA_1_evaluation</td>\n      <td>d_1</td>\n      <td>2011-01-29</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>29</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>5</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################### Merge calendar\n",
    "#################################################################################\n",
    "grid_df = grid_df[MAIN_INDEX]\n",
    "\n",
    "# Merge calendar partly\n",
    "icols = ['date',\n",
    "         'd',\n",
    "         'event_name_1',\n",
    "         'event_type_1',\n",
    "         'event_name_2',\n",
    "         'event_type_2',\n",
    "         'snap_CA',\n",
    "         'snap_TX',\n",
    "         'snap_WI']\n",
    "\n",
    "grid_df = grid_df.merge(calendar_df[icols], on=['d'], how='left')\n",
    "\n",
    "# Minify data\n",
    "# 'snap_' columns we can convert to bool or int8\n",
    "icols = ['event_name_1',\n",
    "         'event_type_1',\n",
    "         'event_name_2',\n",
    "         'event_type_2',\n",
    "         'snap_CA',\n",
    "         'snap_TX',\n",
    "         'snap_WI']\n",
    "for col in icols:\n",
    "    grid_df[col] = grid_df[col].astype('category')\n",
    "\n",
    "# Convert to DateTime\n",
    "grid_df['date'] = pd.to_datetime(grid_df['date'])\n",
    "\n",
    "# Make some features from date\n",
    "grid_df['tm_d'] = grid_df['date'].dt.day.astype(np.int8)\n",
    "grid_df['tm_w'] = grid_df['date'].dt.isocalendar().week.astype(np.int8)\n",
    "grid_df['tm_m'] = grid_df['date'].dt.month.astype(np.int8)\n",
    "grid_df['tm_y'] = grid_df['date'].dt.year\n",
    "grid_df['tm_y'] = (grid_df['tm_y'] - grid_df['tm_y'].min()).astype(np.int8)\n",
    "grid_df['tm_wm'] = grid_df['tm_d'].apply(lambda x: ceil(x/7)).astype(np.int8) # 오늘 몇째주?\n",
    "\n",
    "grid_df['tm_dw'] = grid_df['date'].dt.dayofweek.astype(np.int8) \n",
    "grid_df['tm_w_end'] = (grid_df['tm_dw']>=5).astype(np.int8)\n",
    "\n",
    "display(grid_df.head())\n",
    "\n",
    "# Remove date\n",
    "del grid_df['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T21:54:41.136152Z",
     "start_time": "2024-03-12T21:54:35.255160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save part 3\n",
      "Size: (47735397, 16)\n"
     ]
    }
   ],
   "source": [
    "########################### Save part 3 (Dates)\n",
    "#################################################################################\n",
    "print('Save part 3')\n",
    "\n",
    "# Safe part 3\n",
    "grid_df.to_pickle(processed_data_dir+'grid_part_3.pkl')\n",
    "print('Size:', grid_df.shape)\n",
    "\n",
    "# We don't need calendar_df anymore\n",
    "del calendar_df\n",
    "del grid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T21:55:09.997437Z",
     "start_time": "2024-03-12T21:54:46.438164Z"
    }
   },
   "outputs": [],
   "source": [
    "########################### Some additional cleaning\n",
    "#################################################################################\n",
    "\n",
    "## Part 1\n",
    "# Convert 'd' to int\n",
    "grid_df = pd.read_pickle(processed_data_dir+'grid_part_1.pkl')\n",
    "grid_df['d'] = grid_df['d'].apply(lambda x: x[2:]).astype(np.int16)\n",
    "\n",
    "# Remove 'wm_yr_wk'\n",
    "# as test values are not in train set\n",
    "del grid_df['wm_yr_wk']\n",
    "grid_df.to_pickle(processed_data_dir+'grid_part_1.pkl')\n",
    "\n",
    "del grid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Part2\n",
    "- Lag featrue\n",
    "- Lag rolling feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T22:47:07.647955Z",
     "start_time": "2024-04-02T22:02:48.381780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create lags\n",
      "LAG DAYS [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anwender\\AppData\\Local\\Temp\\ipykernel_22592\\598446025.py:18: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  '{}_lag_{}'.format(col, l): grid_df.groupby(['id'])[col].transform(lambda x: x.shift(l))\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                     id     d  sales  sales_lag_28  \\\n0         HOBBIES_1_008_CA_1_evaluation     1   12.0           NaN   \n1         HOBBIES_1_009_CA_1_evaluation     1    2.0           NaN   \n2         HOBBIES_1_010_CA_1_evaluation     1    0.0           NaN   \n3         HOBBIES_1_012_CA_1_evaluation     1    0.0           NaN   \n4         HOBBIES_1_015_CA_1_evaluation     1    4.0           NaN   \n...                                 ...   ...    ...           ...   \n47735392    FOODS_3_823_WI_3_evaluation  1969    NaN           1.0   \n47735393    FOODS_3_824_WI_3_evaluation  1969    NaN           0.0   \n47735394    FOODS_3_825_WI_3_evaluation  1969    NaN           2.0   \n47735395    FOODS_3_826_WI_3_evaluation  1969    NaN           0.0   \n47735396    FOODS_3_827_WI_3_evaluation  1969    NaN           1.0   \n\n          sales_lag_29  sales_lag_30  sales_lag_31  sales_lag_32  \\\n0                  NaN           NaN           NaN           NaN   \n1                  NaN           NaN           NaN           NaN   \n2                  NaN           NaN           NaN           NaN   \n3                  NaN           NaN           NaN           NaN   \n4                  NaN           NaN           NaN           NaN   \n...                ...           ...           ...           ...   \n47735392           1.0           0.0           0.0           1.0   \n47735393           1.0           0.0           1.0           0.0   \n47735394           0.0           1.0           0.0           1.0   \n47735395           1.0           1.0           1.0           0.0   \n47735396           5.0           2.0           2.0           0.0   \n\n          sales_lag_33  sales_lag_34  sales_lag_35  sales_lag_36  \\\n0                  NaN           NaN           NaN           NaN   \n1                  NaN           NaN           NaN           NaN   \n2                  NaN           NaN           NaN           NaN   \n3                  NaN           NaN           NaN           NaN   \n4                  NaN           NaN           NaN           NaN   \n...                ...           ...           ...           ...   \n47735392           1.0           0.0           3.0           0.0   \n47735393           0.0           0.0           0.0           0.0   \n47735394           0.0           2.0           1.0           0.0   \n47735395           6.0           4.0           1.0           1.0   \n47735396           4.0           5.0           0.0           2.0   \n\n          sales_lag_37  sales_lag_38  sales_lag_39  sales_lag_40  \\\n0                  NaN           NaN           NaN           NaN   \n1                  NaN           NaN           NaN           NaN   \n2                  NaN           NaN           NaN           NaN   \n3                  NaN           NaN           NaN           NaN   \n4                  NaN           NaN           NaN           NaN   \n...                ...           ...           ...           ...   \n47735392           1.0           0.0           1.0           0.0   \n47735393           0.0           0.0           0.0           0.0   \n47735394           0.0           1.0           3.0           3.0   \n47735395           1.0           1.0           2.0           0.0   \n47735396           1.0           0.0           0.0           0.0   \n\n          sales_lag_41  sales_lag_42  \n0                  NaN           NaN  \n1                  NaN           NaN  \n2                  NaN           NaN  \n3                  NaN           NaN  \n4                  NaN           NaN  \n...                ...           ...  \n47735392           0.0           1.0  \n47735393           0.0           0.0  \n47735394           0.0           1.0  \n47735395           1.0           1.0  \n47735396           1.0           1.0  \n\n[47735397 rows x 18 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>d</th>\n      <th>sales</th>\n      <th>sales_lag_28</th>\n      <th>sales_lag_29</th>\n      <th>sales_lag_30</th>\n      <th>sales_lag_31</th>\n      <th>sales_lag_32</th>\n      <th>sales_lag_33</th>\n      <th>sales_lag_34</th>\n      <th>sales_lag_35</th>\n      <th>sales_lag_36</th>\n      <th>sales_lag_37</th>\n      <th>sales_lag_38</th>\n      <th>sales_lag_39</th>\n      <th>sales_lag_40</th>\n      <th>sales_lag_41</th>\n      <th>sales_lag_42</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HOBBIES_1_008_CA_1_evaluation</td>\n      <td>1</td>\n      <td>12.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HOBBIES_1_009_CA_1_evaluation</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HOBBIES_1_010_CA_1_evaluation</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HOBBIES_1_012_CA_1_evaluation</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HOBBIES_1_015_CA_1_evaluation</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>47735392</th>\n      <td>FOODS_3_823_WI_3_evaluation</td>\n      <td>1969</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>47735393</th>\n      <td>FOODS_3_824_WI_3_evaluation</td>\n      <td>1969</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>47735394</th>\n      <td>FOODS_3_825_WI_3_evaluation</td>\n      <td>1969</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>47735395</th>\n      <td>FOODS_3_826_WI_3_evaluation</td>\n      <td>1969</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>47735396</th>\n      <td>FOODS_3_827_WI_3_evaluation</td>\n      <td>1969</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>47735397 rows × 18 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.55 min: Lags\n",
      "Create rolling aggs\n",
      "Rolling period: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anwender\\AppData\\Local\\Temp\\ipykernel_22592\\598446025.py:40: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grid_df['rolling_mean_'+str(i)] = grid_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(SHIFT_DAY).rolling(i).mean()).astype(np.float16)\n",
      "C:\\Users\\Anwender\\AppData\\Local\\Temp\\ipykernel_22592\\598446025.py:41: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grid_df['rolling_std_'+str(i)]  = grid_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(SHIFT_DAY).rolling(i).std()).astype(np.float16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolling period: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anwender\\AppData\\Local\\Temp\\ipykernel_22592\\598446025.py:40: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grid_df['rolling_mean_'+str(i)] = grid_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(SHIFT_DAY).rolling(i).mean()).astype(np.float16)\n",
      "C:\\Users\\Anwender\\AppData\\Local\\Temp\\ipykernel_22592\\598446025.py:41: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grid_df['rolling_std_'+str(i)]  = grid_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(SHIFT_DAY).rolling(i).std()).astype(np.float16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolling period: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anwender\\AppData\\Local\\Temp\\ipykernel_22592\\598446025.py:40: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grid_df['rolling_mean_'+str(i)] = grid_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(SHIFT_DAY).rolling(i).mean()).astype(np.float16)\n",
      "C:\\Users\\Anwender\\AppData\\Local\\Temp\\ipykernel_22592\\598446025.py:41: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grid_df['rolling_std_'+str(i)]  = grid_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(SHIFT_DAY).rolling(i).std()).astype(np.float16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolling period: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anwender\\AppData\\Local\\Temp\\ipykernel_22592\\598446025.py:40: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grid_df['rolling_mean_'+str(i)] = grid_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(SHIFT_DAY).rolling(i).mean()).astype(np.float16)\n",
      "C:\\Users\\Anwender\\AppData\\Local\\Temp\\ipykernel_22592\\598446025.py:41: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grid_df['rolling_std_'+str(i)]  = grid_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(SHIFT_DAY).rolling(i).std()).astype(np.float16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolling period: 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anwender\\AppData\\Local\\Temp\\ipykernel_22592\\598446025.py:40: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grid_df['rolling_mean_'+str(i)] = grid_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(SHIFT_DAY).rolling(i).mean()).astype(np.float16)\n",
      "C:\\Users\\Anwender\\AppData\\Local\\Temp\\ipykernel_22592\\598446025.py:41: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grid_df['rolling_std_'+str(i)]  = grid_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(SHIFT_DAY).rolling(i).std()).astype(np.float16)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                     id     d  sales  sales_lag_28  \\\n0         HOBBIES_1_008_CA_1_evaluation     1   12.0           NaN   \n1         HOBBIES_1_009_CA_1_evaluation     1    2.0           NaN   \n2         HOBBIES_1_010_CA_1_evaluation     1    0.0           NaN   \n3         HOBBIES_1_012_CA_1_evaluation     1    0.0           NaN   \n4         HOBBIES_1_015_CA_1_evaluation     1    4.0           NaN   \n...                                 ...   ...    ...           ...   \n47735392    FOODS_3_823_WI_3_evaluation  1969    NaN           1.0   \n47735393    FOODS_3_824_WI_3_evaluation  1969    NaN           0.0   \n47735394    FOODS_3_825_WI_3_evaluation  1969    NaN           2.0   \n47735395    FOODS_3_826_WI_3_evaluation  1969    NaN           0.0   \n47735396    FOODS_3_827_WI_3_evaluation  1969    NaN           1.0   \n\n          sales_lag_29  sales_lag_30  sales_lag_31  sales_lag_32  \\\n0                  NaN           NaN           NaN           NaN   \n1                  NaN           NaN           NaN           NaN   \n2                  NaN           NaN           NaN           NaN   \n3                  NaN           NaN           NaN           NaN   \n4                  NaN           NaN           NaN           NaN   \n...                ...           ...           ...           ...   \n47735392           1.0           0.0           0.0           1.0   \n47735393           1.0           0.0           1.0           0.0   \n47735394           0.0           1.0           0.0           1.0   \n47735395           1.0           1.0           1.0           0.0   \n47735396           5.0           2.0           2.0           0.0   \n\n          sales_lag_33  sales_lag_34  ...  rolling_mean_7  rolling_std_7  \\\n0                  NaN           NaN  ...             NaN            NaN   \n1                  NaN           NaN  ...             NaN            NaN   \n2                  NaN           NaN  ...             NaN            NaN   \n3                  NaN           NaN  ...             NaN            NaN   \n4                  NaN           NaN  ...             NaN            NaN   \n...                ...           ...  ...             ...            ...   \n47735392           1.0           0.0  ...        0.571289       0.534668   \n47735393           0.0           0.0  ...        0.285645       0.488037   \n47735394           0.0           2.0  ...        0.856934       0.899902   \n47735395           6.0           4.0  ...        1.857422       2.267578   \n47735396           4.0           5.0  ...        2.714844       1.975586   \n\n          rolling_mean_14  rolling_std_14  rolling_mean_30  rolling_std_30  \\\n0                     NaN             NaN              NaN             NaN   \n1                     NaN             NaN              NaN             NaN   \n2                     NaN             NaN              NaN             NaN   \n3                     NaN             NaN              NaN             NaN   \n4                     NaN             NaN              NaN             NaN   \n...                   ...             ...              ...             ...   \n47735392         0.643066        0.841797         0.633301        0.808594   \n47735393         0.142822        0.363037         0.300049        0.535156   \n47735394         1.000000        1.109375         0.766602        0.897461   \n47735395         1.428711        1.650391         1.366211        1.299805   \n47735396         1.642578        1.823242         1.166992        1.463867   \n\n          rolling_mean_60  rolling_std_60  rolling_mean_180  rolling_std_180  \n0                     NaN             NaN               NaN              NaN  \n1                     NaN             NaN               NaN              NaN  \n2                     NaN             NaN               NaN              NaN  \n3                     NaN             NaN               NaN              NaN  \n4                     NaN             NaN               NaN              NaN  \n...                   ...             ...               ...              ...  \n47735392         0.399902        0.717773          0.605469         0.982910  \n47735393         0.283447        0.523926          0.094421         0.329102  \n47735394         0.833496        1.028320          0.850098         0.959961  \n47735395         1.183594        1.213867          1.216797         1.317383  \n47735396         1.250000        1.642578          1.472656         1.763672  \n\n[47735397 rows x 28 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>d</th>\n      <th>sales</th>\n      <th>sales_lag_28</th>\n      <th>sales_lag_29</th>\n      <th>sales_lag_30</th>\n      <th>sales_lag_31</th>\n      <th>sales_lag_32</th>\n      <th>sales_lag_33</th>\n      <th>sales_lag_34</th>\n      <th>...</th>\n      <th>rolling_mean_7</th>\n      <th>rolling_std_7</th>\n      <th>rolling_mean_14</th>\n      <th>rolling_std_14</th>\n      <th>rolling_mean_30</th>\n      <th>rolling_std_30</th>\n      <th>rolling_mean_60</th>\n      <th>rolling_std_60</th>\n      <th>rolling_mean_180</th>\n      <th>rolling_std_180</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HOBBIES_1_008_CA_1_evaluation</td>\n      <td>1</td>\n      <td>12.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HOBBIES_1_009_CA_1_evaluation</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HOBBIES_1_010_CA_1_evaluation</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HOBBIES_1_012_CA_1_evaluation</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HOBBIES_1_015_CA_1_evaluation</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>47735392</th>\n      <td>FOODS_3_823_WI_3_evaluation</td>\n      <td>1969</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.571289</td>\n      <td>0.534668</td>\n      <td>0.643066</td>\n      <td>0.841797</td>\n      <td>0.633301</td>\n      <td>0.808594</td>\n      <td>0.399902</td>\n      <td>0.717773</td>\n      <td>0.605469</td>\n      <td>0.982910</td>\n    </tr>\n    <tr>\n      <th>47735393</th>\n      <td>FOODS_3_824_WI_3_evaluation</td>\n      <td>1969</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.285645</td>\n      <td>0.488037</td>\n      <td>0.142822</td>\n      <td>0.363037</td>\n      <td>0.300049</td>\n      <td>0.535156</td>\n      <td>0.283447</td>\n      <td>0.523926</td>\n      <td>0.094421</td>\n      <td>0.329102</td>\n    </tr>\n    <tr>\n      <th>47735394</th>\n      <td>FOODS_3_825_WI_3_evaluation</td>\n      <td>1969</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.856934</td>\n      <td>0.899902</td>\n      <td>1.000000</td>\n      <td>1.109375</td>\n      <td>0.766602</td>\n      <td>0.897461</td>\n      <td>0.833496</td>\n      <td>1.028320</td>\n      <td>0.850098</td>\n      <td>0.959961</td>\n    </tr>\n    <tr>\n      <th>47735395</th>\n      <td>FOODS_3_826_WI_3_evaluation</td>\n      <td>1969</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>1.857422</td>\n      <td>2.267578</td>\n      <td>1.428711</td>\n      <td>1.650391</td>\n      <td>1.366211</td>\n      <td>1.299805</td>\n      <td>1.183594</td>\n      <td>1.213867</td>\n      <td>1.216797</td>\n      <td>1.317383</td>\n    </tr>\n    <tr>\n      <th>47735396</th>\n      <td>FOODS_3_827_WI_3_evaluation</td>\n      <td>1969</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>...</td>\n      <td>2.714844</td>\n      <td>1.975586</td>\n      <td>1.642578</td>\n      <td>1.823242</td>\n      <td>1.166992</td>\n      <td>1.463867</td>\n      <td>1.250000</td>\n      <td>1.642578</td>\n      <td>1.472656</td>\n      <td>1.763672</td>\n    </tr>\n  </tbody>\n</table>\n<p>47735397 rows × 28 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shifting period: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anwender\\AppData\\Local\\Temp\\ipykernel_22592\\598446025.py:54: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grid_df[col_name] = grid_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(d_shift).rolling(d_window).mean()).astype(np.float16)\n",
      "C:\\Users\\Anwender\\AppData\\Local\\Temp\\ipykernel_22592\\598446025.py:54: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grid_df[col_name] = grid_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(d_shift).rolling(d_window).mean()).astype(np.float16)\n",
      "C:\\Users\\Anwender\\AppData\\Local\\Temp\\ipykernel_22592\\598446025.py:54: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grid_df[col_name] = grid_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(d_shift).rolling(d_window).mean()).astype(np.float16)\n",
      "C:\\Users\\Anwender\\AppData\\Local\\Temp\\ipykernel_22592\\598446025.py:54: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grid_df[col_name] = grid_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(d_shift).rolling(d_window).mean()).astype(np.float16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shifting period: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anwender\\AppData\\Local\\Temp\\ipykernel_22592\\598446025.py:54: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grid_df[col_name] = grid_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(d_shift).rolling(d_window).mean()).astype(np.float16)\n",
      "C:\\Users\\Anwender\\AppData\\Local\\Temp\\ipykernel_22592\\598446025.py:54: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grid_df[col_name] = grid_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(d_shift).rolling(d_window).mean()).astype(np.float16)\n",
      "C:\\Users\\Anwender\\AppData\\Local\\Temp\\ipykernel_22592\\598446025.py:54: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grid_df[col_name] = grid_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(d_shift).rolling(d_window).mean()).astype(np.float16)\n",
      "C:\\Users\\Anwender\\AppData\\Local\\Temp\\ipykernel_22592\\598446025.py:54: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grid_df[col_name] = grid_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(d_shift).rolling(d_window).mean()).astype(np.float16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shifting period: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anwender\\AppData\\Local\\Temp\\ipykernel_22592\\598446025.py:54: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grid_df[col_name] = grid_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(d_shift).rolling(d_window).mean()).astype(np.float16)\n",
      "C:\\Users\\Anwender\\AppData\\Local\\Temp\\ipykernel_22592\\598446025.py:54: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grid_df[col_name] = grid_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(d_shift).rolling(d_window).mean()).astype(np.float16)\n",
      "C:\\Users\\Anwender\\AppData\\Local\\Temp\\ipykernel_22592\\598446025.py:54: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grid_df[col_name] = grid_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(d_shift).rolling(d_window).mean()).astype(np.float16)\n",
      "C:\\Users\\Anwender\\AppData\\Local\\Temp\\ipykernel_22592\\598446025.py:54: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grid_df[col_name] = grid_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(d_shift).rolling(d_window).mean()).astype(np.float16)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                     id     d  sales  sales_lag_28  \\\n0         HOBBIES_1_008_CA_1_evaluation     1   12.0           NaN   \n1         HOBBIES_1_009_CA_1_evaluation     1    2.0           NaN   \n2         HOBBIES_1_010_CA_1_evaluation     1    0.0           NaN   \n3         HOBBIES_1_012_CA_1_evaluation     1    0.0           NaN   \n4         HOBBIES_1_015_CA_1_evaluation     1    4.0           NaN   \n...                                 ...   ...    ...           ...   \n47735392    FOODS_3_823_WI_3_evaluation  1969    NaN           1.0   \n47735393    FOODS_3_824_WI_3_evaluation  1969    NaN           0.0   \n47735394    FOODS_3_825_WI_3_evaluation  1969    NaN           2.0   \n47735395    FOODS_3_826_WI_3_evaluation  1969    NaN           0.0   \n47735396    FOODS_3_827_WI_3_evaluation  1969    NaN           1.0   \n\n          sales_lag_29  sales_lag_30  sales_lag_31  sales_lag_32  \\\n0                  NaN           NaN           NaN           NaN   \n1                  NaN           NaN           NaN           NaN   \n2                  NaN           NaN           NaN           NaN   \n3                  NaN           NaN           NaN           NaN   \n4                  NaN           NaN           NaN           NaN   \n...                ...           ...           ...           ...   \n47735392           1.0           0.0           0.0           1.0   \n47735393           1.0           0.0           1.0           0.0   \n47735394           0.0           1.0           0.0           1.0   \n47735395           1.0           1.0           1.0           0.0   \n47735396           5.0           2.0           2.0           0.0   \n\n          sales_lag_33  sales_lag_34  ...  rolling_mean_tmp_1_30  \\\n0                  NaN           NaN  ...                    NaN   \n1                  NaN           NaN  ...                    NaN   \n2                  NaN           NaN  ...                    NaN   \n3                  NaN           NaN  ...                    NaN   \n4                  NaN           NaN  ...                    NaN   \n...                ...           ...  ...                    ...   \n47735392           1.0           0.0  ...                    NaN   \n47735393           0.0           0.0  ...                    NaN   \n47735394           0.0           2.0  ...                    NaN   \n47735395           6.0           4.0  ...                    NaN   \n47735396           4.0           5.0  ...                    NaN   \n\n          rolling_mean_tmp_1_60  rolling_mean_tmp_7_7  rolling_mean_tmp_7_14  \\\n0                           NaN                   NaN                    NaN   \n1                           NaN                   NaN                    NaN   \n2                           NaN                   NaN                    NaN   \n3                           NaN                   NaN                    NaN   \n4                           NaN                   NaN                    NaN   \n...                         ...                   ...                    ...   \n47735392                    NaN                   NaN                    NaN   \n47735393                    NaN                   NaN                    NaN   \n47735394                    NaN                   NaN                    NaN   \n47735395                    NaN                   NaN                    NaN   \n47735396                    NaN                   NaN                    NaN   \n\n          rolling_mean_tmp_7_30  rolling_mean_tmp_7_60  rolling_mean_tmp_14_7  \\\n0                           NaN                    NaN                    NaN   \n1                           NaN                    NaN                    NaN   \n2                           NaN                    NaN                    NaN   \n3                           NaN                    NaN                    NaN   \n4                           NaN                    NaN                    NaN   \n...                         ...                    ...                    ...   \n47735392                    NaN                    NaN                    NaN   \n47735393                    NaN                    NaN                    NaN   \n47735394                    NaN                    NaN                    NaN   \n47735395                    NaN                    NaN                    NaN   \n47735396                    NaN                    NaN                    NaN   \n\n          rolling_mean_tmp_14_14  rolling_mean_tmp_14_30  \\\n0                            NaN                     NaN   \n1                            NaN                     NaN   \n2                            NaN                     NaN   \n3                            NaN                     NaN   \n4                            NaN                     NaN   \n...                          ...                     ...   \n47735392                     NaN                     NaN   \n47735393                     NaN                     NaN   \n47735394                     NaN                     NaN   \n47735395                     NaN                     NaN   \n47735396                     NaN                     NaN   \n\n          rolling_mean_tmp_14_60  \n0                            NaN  \n1                            NaN  \n2                            NaN  \n3                            NaN  \n4                            NaN  \n...                          ...  \n47735392                     NaN  \n47735393                     NaN  \n47735394                     NaN  \n47735395                     NaN  \n47735396                     NaN  \n\n[47735397 rows x 40 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>d</th>\n      <th>sales</th>\n      <th>sales_lag_28</th>\n      <th>sales_lag_29</th>\n      <th>sales_lag_30</th>\n      <th>sales_lag_31</th>\n      <th>sales_lag_32</th>\n      <th>sales_lag_33</th>\n      <th>sales_lag_34</th>\n      <th>...</th>\n      <th>rolling_mean_tmp_1_30</th>\n      <th>rolling_mean_tmp_1_60</th>\n      <th>rolling_mean_tmp_7_7</th>\n      <th>rolling_mean_tmp_7_14</th>\n      <th>rolling_mean_tmp_7_30</th>\n      <th>rolling_mean_tmp_7_60</th>\n      <th>rolling_mean_tmp_14_7</th>\n      <th>rolling_mean_tmp_14_14</th>\n      <th>rolling_mean_tmp_14_30</th>\n      <th>rolling_mean_tmp_14_60</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HOBBIES_1_008_CA_1_evaluation</td>\n      <td>1</td>\n      <td>12.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HOBBIES_1_009_CA_1_evaluation</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HOBBIES_1_010_CA_1_evaluation</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HOBBIES_1_012_CA_1_evaluation</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HOBBIES_1_015_CA_1_evaluation</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>47735392</th>\n      <td>FOODS_3_823_WI_3_evaluation</td>\n      <td>1969</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>47735393</th>\n      <td>FOODS_3_824_WI_3_evaluation</td>\n      <td>1969</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>47735394</th>\n      <td>FOODS_3_825_WI_3_evaluation</td>\n      <td>1969</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>47735395</th>\n      <td>FOODS_3_826_WI_3_evaluation</td>\n      <td>1969</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>47735396</th>\n      <td>FOODS_3_827_WI_3_evaluation</td>\n      <td>1969</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>47735397 rows × 40 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.63 min: Lags\n"
     ]
    }
   ],
   "source": [
    "grid_df = pd.read_pickle(processed_data_dir+'processedgrid_part_1.pkl')\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "# We need only 'id','d','sales'\n",
    "# to make lags and rollings\n",
    "grid_df = grid_df[['id','d','sales']]\n",
    "SHIFT_DAY = 28\n",
    "\n",
    "# Lags\n",
    "# with 28 day shift\n",
    "start_time = time.time()\n",
    "print('Create lags')\n",
    "\n",
    "LAG_DAYS = [col for col in range(SHIFT_DAY,SHIFT_DAY+15)]\n",
    "print(\"LAG DAYS\", LAG_DAYS)\n",
    "grid_df = grid_df.assign(**{\n",
    "        '{}_lag_{}'.format(col, l): grid_df.groupby(['id'])[col].transform(lambda x: x.shift(l))\n",
    "        for l in LAG_DAYS\n",
    "        for col in [TARGET]\n",
    "    })\n",
    "\n",
    "display(grid_df)\n",
    "grid_df.to_csv(\"E:/Seminararbeit/Code/A1/2. data/test_lag_days.csv\")\n",
    "\n",
    "# Minify lag columns\n",
    "for col in list(grid_df):\n",
    "    if 'lag' in col:\n",
    "        grid_df[col] = grid_df[col].astype(np.float16)\n",
    "\n",
    "print('%0.2f min: Lags' % ((time.time() - start_time) / 60))\n",
    "\n",
    "# Rollings\n",
    "# with 28 day shift\n",
    "start_time = time.time()\n",
    "print('Create rolling aggs')\n",
    "\n",
    "for i in [7,14,30,60,180]:\n",
    "    print('Rolling period:', i)\n",
    "    grid_df['rolling_mean_'+str(i)] = grid_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(SHIFT_DAY).rolling(i).mean()).astype(np.float16)\n",
    "    grid_df['rolling_std_'+str(i)]  = grid_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(SHIFT_DAY).rolling(i).std()).astype(np.float16)\n",
    "\n",
    "\n",
    "display(grid_df)\n",
    "grid_df.to_csv(\"E:/Seminararbeit/Code/A1/2. data/test_rolling_period.csv\")\n",
    "\n",
    "\n",
    "# Rollings\n",
    "# with sliding shift\n",
    "for d_shift in [1,7,14]: \n",
    "    print('Shifting period:', d_shift)\n",
    "    for d_window in [7,14,30,60]:\n",
    "        col_name = 'rolling_mean_tmp_'+str(d_shift)+'_'+str(d_window)\n",
    "        grid_df[col_name] = grid_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(d_shift).rolling(d_window).mean()).astype(np.float16)\n",
    "    \n",
    "display(grid_df)\n",
    "grid_df.to_csv(\"E:/Seminararbeit/Code/A1/2. data/test_shifting_period.csv\")\n",
    "    \n",
    "print('%0.2f min: Lags' % ((time.time() - start_time) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Export\n",
    "#################################################################################\n",
    "print('Save lags and rollings')\n",
    "\n",
    "grid_df.to_pickle(processed_data_dir+'lags_df_'+str(SHIFT_DAY)+'.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Part3\n",
    "- Mean encoding feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Apply on grid_df\n",
    "#################################################################################\n",
    "# lets read grid from \n",
    "# https://www.kaggle.com/kyakovlev/m5-simple-fe\n",
    "# to be sure that our grids are aligned by index\n",
    "grid_df = pd.read_pickle(processed_data_dir+'grid_part_1.pkl')\n",
    "grid_df['sales'][grid_df['d']>(1941-28)] = np.nan\n",
    "base_cols = list(grid_df)\n",
    "\n",
    "icols =  [\n",
    "            ['state_id'],\n",
    "            ['store_id'],\n",
    "            ['cat_id'],\n",
    "            ['dept_id'],\n",
    "            ['state_id', 'cat_id'],\n",
    "            ['state_id', 'dept_id'],\n",
    "            ['store_id', 'cat_id'],\n",
    "            ['store_id', 'dept_id'],\n",
    "            ['item_id'],\n",
    "            ['item_id', 'state_id'],\n",
    "            ['item_id', 'store_id']\n",
    "            ]\n",
    "\n",
    "for col in icols:\n",
    "    print('Encoding', col)\n",
    "    col_name = '_'+'_'.join(col)+'_'\n",
    "    grid_df['enc'+col_name+'mean'] = grid_df.groupby(col)['sales'].transform('mean').astype(np.float16)\n",
    "    grid_df['enc'+col_name+'std'] = grid_df.groupby(col)['sales'].transform('std').astype(np.float16)\n",
    "\n",
    "keep_cols = [col for col in list(grid_df) if col not in base_cols]\n",
    "grid_df = grid_df[['id','d']+keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "print('Save Mean/Std encoding')\n",
    "grid_df.to_pickle(processed_data_dir+'mean_encoding_df.pkl')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
